{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPeAEeZsmlflQ6mXbYUWajs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sku1978/sk-share-repo/blob/main/Spark/SparkDataFrame/SparkDataFrameNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhiBxUATKbVB"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq  > /dev/null \n",
        "!wget -q https://downloads.apache.org/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz > /dev/null \n",
        "!pip install -q findspark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5veJKNsaD8gv",
        "outputId": "15c9aa47-0f93-436b-d592-36bf7f5368d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mkdir /content/conf /content/lib\n",
        "!wget -O /content/conf/log4j.properties https://raw.githubusercontent.com/sku1978/sk-share-repo/main/Spark/SparkDataFrame/conf/log4j.properties > /dev/null 2>&1\n",
        "!mv /content/spark-3.1.1-bin-hadoop3.2/conf/spark-defaults.conf /content/spark-3.1.1-bin-hadoop3.2/conf/spark-defaults.conf.bk  > /dev/null 2>&1\n",
        "!wget -O /content/spark-3.1.1-bin-hadoop3.2/conf/spark-defaults.conf https://raw.githubusercontent.com/sku1978/sk-share-repo/main/Spark/SparkDataFrame/conf/spark-defaults.conf  > /dev/null 2>&1\n",
        "!wget -O /content/conf/spark.conf https://raw.githubusercontent.com/sku1978/sk-share-repo/main/Spark/SparkDataFrame/conf/spark.conf > /dev/null 2>&1\n",
        "\n",
        "!wget -O /content/lib/logger.py https://raw.githubusercontent.com/sku1978/sk-share-repo/main/Spark/SparkDataFrame/lib/logger.py  > /dev/null 2>&1\n",
        "!wget -O /content/lib/utils.py https://raw.githubusercontent.com/sku1978/sk-share-repo/main/Spark/SparkDataFrame/lib/utils.py  > /dev/null 2>&1"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/conf’: File exists\n",
            "mkdir: cannot create directory ‘/content/lib’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVA-bBFsCPyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4de87a7c-63b4-4dac-8e8e-d69ec5f74b65"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.1.1-bin-hadoop3.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe_e2IaqXMTC"
      },
      "source": [
        "**Spark UI section**\n",
        "<br>To use Spark UI, uncomment below sections and use the public link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhLCqy4a6ihE"
      },
      "source": [
        "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "#!unzip ngrok-stable-linux-amd64.zip\n",
        "#get_ipython().system_raw('./ngrok http 4050 &')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSxhuV046is1"
      },
      "source": [
        "#!curl -s http://localhost:4040/api/tunnels"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PybcmfVuWXgc"
      },
      "source": [
        "**Main Section**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jim-sE5KqDe"
      },
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark import SparkConf, SparkFiles\n",
        "from lib.logger import Log4J\n",
        "from lib.utils import get_spark_app_config\n",
        "\n",
        "conf=get_spark_app_config()\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .config(conf=conf)\\\n",
        "        .getOrCreate()\n",
        "\n",
        "logger = Log4J(spark)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNbHk56QWhH0"
      },
      "source": [
        "**Basic CSV Read**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPD-t1kD5bEI"
      },
      "source": [
        "def load_csv_file(spark, url):\n",
        "   spark.sparkContext.addFile(url)\n",
        "\n",
        "   survey_df=spark.read \\\n",
        "   .format(\"csv\") \\\n",
        "   .option(\"header\", \"true\") \\\n",
        "   .option(\"inferSchema\", \"true\") \\\n",
        "   .option(\"mode\", \"FAILFAST\") \\\n",
        "   .load('file://'+SparkFiles.get(\"sample.csv\"))\n",
        "\n",
        "   return survey_df\n",
        "\n",
        "def count_by_country(survey_df):\n",
        "  count_df= survey_df.select(\"Age\", \"Gender\", \"Country\", \"State\") \\\n",
        "                     .where(\"Age <= 40\") \\\n",
        "                     .groupBy(\"Country\") \\\n",
        "                     .count()\n",
        "  return count_df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSfkRz_HWQL-"
      },
      "source": [
        "logger.info(\"Start CSV Load\")\n",
        "\n",
        "url='https://raw.githubusercontent.com/sku1978/sk-share-repo/main/Spark/SparkDataFrame/data/sample.csv'\n",
        "\n",
        "survey_df=load_csv_file(spark, url)\n",
        "partitioned_survey_df=survey_df.repartition(2)\n",
        "\n",
        "count_df=count_by_country(partitioned_survey_df)\n",
        "\n",
        "logger.info(count_df.collect())\n",
        "\n",
        "logger.info(\"End CSV Load\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgrObFdrXOso"
      },
      "source": [
        "**Data Types**<br>\n",
        "(https://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html#module-pyspark.sql.types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fy1u9idX4yC"
      },
      "source": [
        "**CSV Read (CSV)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhAtshrmYDDh",
        "outputId": "215ce566-a8b3-41ca-c58c-f6b7b6f735f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, DateType, StringType\n",
        "\n",
        "logger.info(\"Start Flight Time CSV Load\")\n",
        "\n",
        "url='https://raw.githubusercontent.com/sku1978/sk-share-repo/main/Spark/SparkDataFrame/data/flight-time.csv'\n",
        "\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "flightSchemaStruct = StructType([StructField(\"FL_DATE\", DateType(), True),\n",
        "                                 StructField(\"OP_CARRIER\", StringType(), True),\n",
        "                                 StructField(\"OP_CARRIER_FL_NUM\", IntegerType(), True),\n",
        "                                 StructField(\"ORIGIN\", StringType(), True),\n",
        "                                 StructField(\"ORIGIN_CITY_NAME\", StringType(), True),\n",
        "                                 StructField(\"DEST\", StringType(), True),\n",
        "                                 StructField(\"DEST_CITY_NAME\", StringType(), True),\n",
        "                                 StructField(\"CRS_DEP_TIME\", IntegerType(), True),\n",
        "                                 StructField(\"DEP_TIME\", IntegerType(), True),\n",
        "                                 StructField(\"WHEELS_ON\", IntegerType(), True),\n",
        "                                 StructField(\"TAXI_IN\", IntegerType(), True),\n",
        "                                 StructField(\"CRS_ARR_TIME\", IntegerType(), True),\n",
        "                                 StructField(\"ARR_TIME\", IntegerType(), True),\n",
        "                                 StructField(\"CANCELLED\", IntegerType(), True),\n",
        "                                 StructField(\"DISTANCE\", StringType(), True),\n",
        "                                ])\n",
        "\n",
        "flight_time_df=spark.read \\\n",
        "                    .format(\"csv\") \\\n",
        "                    .option(\"header\", \"true\") \\\n",
        "                    .option(\"mode\", \"FAILFAST\") \\\n",
        "                    .option(\"dateFormat\", \"M/d/y\") \\\n",
        "                    .schema(flightSchemaStruct) \\\n",
        "                    .load('file://'+SparkFiles.get(\"flight-time.csv\"))\n",
        "\n",
        "flight_time_df.show()\n",
        "\n",
        "logger.info(\"End CSV Load\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|ORIGIN_CITY_NAME|DEST|DEST_CITY_NAME|CRS_DEP_TIME|DEP_TIME|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|CANCELLED|DISTANCE|\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "|2000-01-01|        DL|             1451|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1115|    1113|     1343|      5|        1400|    1348|        0|     946|\n",
            "|2000-01-01|        DL|             1479|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1315|    1311|     1536|      7|        1559|    1543|        0|     946|\n",
            "|2000-01-01|        DL|             1857|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1415|    1414|     1642|      9|        1721|    1651|        0|     946|\n",
            "|2000-01-01|        DL|             1997|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1715|    1720|     1955|     10|        2013|    2005|        0|     946|\n",
            "|2000-01-01|        DL|             2065|   BOS|      Boston, MA| ATL|   Atlanta, GA|        2015|    2010|     2230|     10|        2300|    2240|        0|     946|\n",
            "|2000-01-01|        US|             2619|   BOS|      Boston, MA| ATL|   Atlanta, GA|         650|     649|      956|      7|         955|    1003|        0|     946|\n",
            "|2000-01-01|        US|             2621|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1440|    1446|     1713|      4|        1738|    1717|        0|     946|\n",
            "|2000-01-01|        DL|              346|   BTR| Baton Rouge, LA| ATL|   Atlanta, GA|        1740|    1744|     1957|      9|        2008|    2006|        0|     449|\n",
            "|2000-01-01|        DL|              412|   BTR| Baton Rouge, LA| ATL|   Atlanta, GA|        1345|    1345|     1552|      9|        1622|    1601|        0|     449|\n",
            "|2000-01-01|        DL|              299|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|        1245|    1245|     1443|      5|        1455|    1448|        0|     712|\n",
            "|2000-01-01|        DL|              495|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|        2035|    2035|     2226|      9|        2241|    2235|        0|     712|\n",
            "|2000-01-01|        DL|              677|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|         710|     710|      940|      7|         925|     947|        0|     712|\n",
            "|2000-01-01|        DL|              251|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        2040|    2100|     2235|      7|        2233|    2242|        0|     576|\n",
            "|2000-01-01|        DL|             1003|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1635|    1838|     2020|     12|        1832|    2032|        0|     576|\n",
            "|2000-01-01|        DL|             1501|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1430|    1435|     1623|     12|        1634|    1635|        0|     576|\n",
            "|2000-01-01|        DL|             1907|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|         530|     530|      716|      4|         723|     720|        0|     576|\n",
            "|2000-01-01|        DL|             2063|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1250|    null|     null|   null|        1449|    null|        1|     576|\n",
            "|2000-01-01|        DL|             2111|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1845|    1855|     2041|      9|        2046|    2050|        0|     576|\n",
            "|2000-01-01|        US|             2632|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|         710|     710|     null|   null|         905|    null|        0|     576|\n",
            "|2000-01-01|        US|             2967|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1700|    1700|     1845|      6|        1853|    1851|        0|     576|\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2uWblhdVR6Q"
      },
      "source": [
        "**JSON Read**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZYy8bFcVUYP",
        "outputId": "74ca68a3-0b49-4bbd-ff53-386225abb9c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "logger.info(\"Start Flight Time JSON Load\")\n",
        "\n",
        "url='https://raw.githubusercontent.com/sku1978/sk-share-repo/main/Spark/SparkDataFrame/data/flight-time.json'\n",
        "\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "flightSchemaDDL = \"\"\"FL_DATE DATE, \n",
        "                     OP_CARRIER STRING, \n",
        "                     OP_CARRIER_FL_NUM INT,\n",
        "                     ORIGIN STRING,\n",
        "                     ORIGIN_CITY_NAME STRING,\n",
        "                     DEST STRING,\n",
        "                     DEST_CITY_NAME STRING,\n",
        "                     CRS_DEP_TIME INT,\n",
        "                     DEP_TIME INT,\n",
        "                     WHEELS_ON INT,\n",
        "                     TAXI_IN INT,\n",
        "                     CRS_ARR_TIME INT,\n",
        "                     ARR_TIME INT,\n",
        "                     CANCELLED INT,\n",
        "                     DISTANCE STRING\"\"\"\n",
        "\n",
        "flight_time_df=spark.read \\\n",
        "                    .format(\"json\") \\\n",
        "                    .option(\"dateFormat\", \"M/d/y\") \\\n",
        "                    .schema(flightSchemaDDL) \\\n",
        "                    .load('file://'+SparkFiles.get(\"flight-time.json\"))\n",
        "\n",
        "flight_time_df.show()\n",
        "\n",
        "logger.info(\"End JSON Load\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|ORIGIN_CITY_NAME|DEST|DEST_CITY_NAME|CRS_DEP_TIME|DEP_TIME|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|CANCELLED|DISTANCE|\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "|2000-01-01|        DL|             1451|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1115|    1113|     1343|      5|        1400|    1348|        0|     946|\n",
            "|2000-01-01|        DL|             1479|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1315|    1311|     1536|      7|        1559|    1543|        0|     946|\n",
            "|2000-01-01|        DL|             1857|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1415|    1414|     1642|      9|        1721|    1651|        0|     946|\n",
            "|2000-01-01|        DL|             1997|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1715|    1720|     1955|     10|        2013|    2005|        0|     946|\n",
            "|2000-01-01|        DL|             2065|   BOS|      Boston, MA| ATL|   Atlanta, GA|        2015|    2010|     2230|     10|        2300|    2240|        0|     946|\n",
            "|2000-01-01|        US|             2619|   BOS|      Boston, MA| ATL|   Atlanta, GA|         650|     649|      956|      7|         955|    1003|        0|     946|\n",
            "|2000-01-01|        US|             2621|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1440|    1446|     1713|      4|        1738|    1717|        0|     946|\n",
            "|2000-01-01|        DL|              346|   BTR| Baton Rouge, LA| ATL|   Atlanta, GA|        1740|    1744|     1957|      9|        2008|    2006|        0|     449|\n",
            "|2000-01-01|        DL|              412|   BTR| Baton Rouge, LA| ATL|   Atlanta, GA|        1345|    1345|     1552|      9|        1622|    1601|        0|     449|\n",
            "|2000-01-01|        DL|              299|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|        1245|    1245|     1443|      5|        1455|    1448|        0|     712|\n",
            "|2000-01-01|        DL|              495|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|        2035|    2035|     2226|      9|        2241|    2235|        0|     712|\n",
            "|2000-01-01|        DL|              677|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|         710|     710|      940|      7|         925|     947|        0|     712|\n",
            "|2000-01-01|        DL|              251|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        2040|    2100|     2235|      7|        2233|    2242|        0|     576|\n",
            "|2000-01-01|        DL|             1003|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1635|    1838|     2020|     12|        1832|    2032|        0|     576|\n",
            "|2000-01-01|        DL|             1501|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1430|    1435|     1623|     12|        1634|    1635|        0|     576|\n",
            "|2000-01-01|        DL|             1907|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|         530|     530|      716|      4|         723|     720|        0|     576|\n",
            "|2000-01-01|        DL|             2063|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1250|    null|     null|   null|        1449|    null|        1|     576|\n",
            "|2000-01-01|        DL|             2111|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1845|    1855|     2041|      9|        2046|    2050|        0|     576|\n",
            "|2000-01-01|        US|             2632|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|         710|     710|     null|   null|         905|    null|        0|     576|\n",
            "|2000-01-01|        US|             2967|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1700|    1700|     1845|      6|        1853|    1851|        0|     576|\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQiEpwe1V2ii"
      },
      "source": [
        "**Parquet Read**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zW8xC5BV48M",
        "outputId": "482c1fd0-81ea-4097-9021-b992193f407e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "logger.info(\"Start Flight Time Parquet Load\")\n",
        "\n",
        "url='https://raw.githubusercontent.com/sku1978/sk-share-repo/main/Spark/SparkDataFrame/data/flight-time.parquet'\n",
        "\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "flight_time_df=spark.read \\\n",
        "                    .format(\"parquet\") \\\n",
        "                    .option(\"inferSchema\", \"true\") \\\n",
        "                    .load('file://'+SparkFiles.get(\"flight-time.parquet\"))\n",
        "\n",
        "flight_time_df.show()\n",
        "\n",
        "logger.info(\"End Parquet Load\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|ORIGIN_CITY_NAME|DEST|DEST_CITY_NAME|CRS_DEP_TIME|DEP_TIME|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|CANCELLED|DISTANCE|\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "|2000-01-01|        DL|             1451|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1115|    1113|     1343|      5|        1400|    1348|        0|     946|\n",
            "|2000-01-01|        DL|             1479|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1315|    1311|     1536|      7|        1559|    1543|        0|     946|\n",
            "|2000-01-01|        DL|             1857|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1415|    1414|     1642|      9|        1721|    1651|        0|     946|\n",
            "|2000-01-01|        DL|             1997|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1715|    1720|     1955|     10|        2013|    2005|        0|     946|\n",
            "|2000-01-01|        DL|             2065|   BOS|      Boston, MA| ATL|   Atlanta, GA|        2015|    2010|     2230|     10|        2300|    2240|        0|     946|\n",
            "|2000-01-01|        US|             2619|   BOS|      Boston, MA| ATL|   Atlanta, GA|         650|     649|      956|      7|         955|    1003|        0|     946|\n",
            "|2000-01-01|        US|             2621|   BOS|      Boston, MA| ATL|   Atlanta, GA|        1440|    1446|     1713|      4|        1738|    1717|        0|     946|\n",
            "|2000-01-01|        DL|              346|   BTR| Baton Rouge, LA| ATL|   Atlanta, GA|        1740|    1744|     1957|      9|        2008|    2006|        0|     449|\n",
            "|2000-01-01|        DL|              412|   BTR| Baton Rouge, LA| ATL|   Atlanta, GA|        1345|    1345|     1552|      9|        1622|    1601|        0|     449|\n",
            "|2000-01-01|        DL|              299|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|        1245|    1245|     1443|      5|        1455|    1448|        0|     712|\n",
            "|2000-01-01|        DL|              495|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|        2035|    2035|     2226|      9|        2241|    2235|        0|     712|\n",
            "|2000-01-01|        DL|              677|   BUF|     Buffalo, NY| ATL|   Atlanta, GA|         710|     710|      940|      7|         925|     947|        0|     712|\n",
            "|2000-01-01|        DL|              251|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        2040|    2100|     2235|      7|        2233|    2242|        0|     576|\n",
            "|2000-01-01|        DL|             1003|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1635|    1838|     2020|     12|        1832|    2032|        0|     576|\n",
            "|2000-01-01|        DL|             1501|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1430|    1435|     1623|     12|        1634|    1635|        0|     576|\n",
            "|2000-01-01|        DL|             1907|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|         530|     530|      716|      4|         723|     720|        0|     576|\n",
            "|2000-01-01|        DL|             2063|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1250|    null|     null|   null|        1449|    null|        1|     576|\n",
            "|2000-01-01|        DL|             2111|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1845|    1855|     2041|      9|        2046|    2050|        0|     576|\n",
            "|2000-01-01|        US|             2632|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|         710|     710|     null|   null|         905|    null|        0|     576|\n",
            "|2000-01-01|        US|             2967|   BWI|   Baltimore, MD| ATL|   Atlanta, GA|        1700|    1700|     1845|      6|        1853|    1851|        0|     576|\n",
            "+----------+----------+-----------------+------+----------------+----+--------------+------------+--------+---------+-------+------------+--------+---------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPHyggQ0l_fL"
      },
      "source": [
        "**Write Avro file**<br>\n",
        "Added <br>\n",
        "spark.jars.packages                org.apache.spark:spark-avro_2.12:3.0.0\n",
        "<br>to<br>\n",
        "conf/spark-defaults.conf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwGZu8xamR5o",
        "outputId": "24785151-4d3c-474e-8034-fa177ffabf3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "logger.info(\"Start Flight Time Parquet Load\")\n",
        "\n",
        "url='https://raw.githubusercontent.com/sku1978/sk-share-repo/main/Spark/SparkDataFrame/data/flight-time.parquet'\n",
        "\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "flight_time_df=spark.read \\\n",
        "                    .format(\"parquet\") \\\n",
        "                    .option(\"inferSchema\", \"true\") \\\n",
        "                    .load('file://'+SparkFiles.get(\"flight-time.parquet\"))\n",
        "\n",
        "logger.info(\"End Parquet Load\")\n",
        "\n",
        "logger.info(\"Start Avro write\")\n",
        "logger.info(\"Number of partitions: \" + str(flight_time_df.rdd.getNumPartitions()))\n",
        "\n",
        "flight_time_df.write \\\n",
        "              .format(\"avro\") \\\n",
        "              .mode(\"overwrite\") \\\n",
        "              .option(\"path\", \"dataSink/avro/\") \\\n",
        "              .save()\n",
        "\n",
        "logger.info(\"End Avro write\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-5d5eced5d616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of partitions: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflight_time_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNumPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mflight_time_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m               \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"avro\"\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataSink/avro/\"\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End Avro write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: Failed to find data source: avro. Avro is built-in but external data source module since Spark 2.4. Please deploy the application as per the deployment section of \"Apache Avro Data Source Guide\"."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pkC1hvOncFm",
        "outputId": "871adbf7-a789-4cc7-ec5a-f0b019701494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piuP7dIZXBM5"
      },
      "source": [
        "**View Log**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRtr-fRE5_3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8f117a-be28-412f-ede4-e33db08710ba"
      },
      "source": [
        "!cat app-logs/sparklog.log"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21/04/08 16:33:03 INFO Hello World: Start CSV Load\n",
            "21/04/08 16:33:14 INFO Hello World: [[United Kingdom, 1], [Canada, 2], [United States, 4]]\n",
            "21/04/08 16:33:14 INFO Hello World: End CSV Load\n",
            "21/04/08 16:33:14 INFO Hello World: Start Flight Time CSV Load\n",
            "21/04/08 16:33:20 INFO Hello World: End CSV Load\n",
            "21/04/08 16:34:55 INFO Hello World: Start Flight Time JSON Load\n",
            "21/04/08 16:35:01 INFO Hello World: End JSON Load\n",
            "21/04/08 16:37:03 INFO Hello World: Start Flight Time Parquet Load\n",
            "21/04/08 16:37:06 INFO Hello World: End JSON Load\n",
            "21/04/08 16:45:12 INFO Hello World: Start Flight Time CSV Load\n",
            "21/04/08 16:45:15 INFO Hello World: End CSV Load\n",
            "21/04/08 17:08:47 INFO Hello World: Start Flight Time CSV Load\n",
            "21/04/08 17:11:48 INFO Hello World: Start Flight Time CSV Load\n",
            "21/04/08 17:12:23 INFO Hello World: Start Flight Time CSV Load\n",
            "21/04/08 17:12:23 INFO Hello World: End CSV Load\n",
            "21/04/08 17:12:49 INFO Hello World: Start Flight Time CSV Load\n",
            "21/04/08 17:12:49 INFO Hello World: End CSV Load\n",
            "21/04/08 17:18:18 INFO Hello World: Start Flight Time JSON Load\n",
            "21/04/08 17:18:18 INFO Hello World: End JSON Load\n",
            "21/04/08 17:45:22 INFO Hello World: Start Flight Time JSON Load\n",
            "21/04/08 17:45:22 INFO Hello World: End JSON Load\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}